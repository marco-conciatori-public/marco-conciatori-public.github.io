<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mantis - Capabilities</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
    <link rel="icon" type="image/png" href="assets/all/tab_icon.png">
</head>
<body class="antialiased">
<div id="navbar-placeholder"></div>

<!-- Main Page Layout with Side Menu -->
<div class="container mx-auto px-4 py-8">
    <div class="lg:grid lg:grid-cols-12 lg:gap-8">

        <!-- Side Navigation (Sticky on large screens) -->
        <aside class="hidden lg:block lg:col-span-2 lg:sticky lg:top-24 self-start">
            <nav class="p-4 rounded-lg bg-gray-50 border">
                <h4 class="element-title">Capabilities</h4>
                <ul class="space-y-2" id="side-nav-links">
                    <li><a href="#omnidirectional-movement" class="side-nav-link">Omnidirectional Movement</a></li>
                    <li><a href="#robotic-arm" class="side-nav-link">Robotic Arm</a></li>
                    <li><a href="#computer-vision" class="side-nav-link">Computer Vision</a></li>
                    <li><a href="#autonomous-agent-vision" class="side-nav-link">Autonomous Agent (Vision)</a></li>
                    <li><a href="#autonomous-agent-sound" class="side-nav-link">Autonomous Agent (Sound)</a></li>
                    <li><a href="#voice-interaction" class="side-nav-link">Voice Interaction</a></li>
                    <li><a href="#obstacle-avoidance" class="side-nav-link">Obstacle Avoidance</a></li>
                    <li><a href="#vr-connection" class="side-nav-link">VR Connection</a></li>
                </ul>
            </nav>
        </aside>

        <!-- Main Content -->
        <main class="lg:col-span-10">
            <div class="bg-white p-8 sm:p-12 rounded-lg shadow-md">
                <h2 class="page-title">What Mantis Can Do</h2>

                <!-- Movement Section -->
                <section id="omnidirectional-movement" class="standard-section">
                    <h3 class="section-title">Omnidirectional Movement</h3>
                    <div class="grid md:grid-cols-12 gap-8 items-center">
                        <div class="md:col-span-7">
                            <p class="standard-text">
                                Mantis has four mecanum wheels, which grant it the ability to move forward, backward, sideways,
                                and rotate on the spot. This omnidirectional movement allows it to navigate tight spaces and
                                complex environments with ease. Mecanum wheels work best on surfaces that are not too smooth,
                                nor too uneven.
                            </p>
                            <p class="standard-text">
                                For precise control, the speed can be adjusted in real time between 10% and 100% of the maximum
                                velocity using the controller.
                                This affects all form of movement, including autonomous navigation and arm speed.
                            </p>
                        </div>
                        <div class="md:col-span-5">
                            <img src="assets/capabilities/mecanum_wheels.png" alt="Mantis Omnidirectional Wheels" class="rounded-lg w-full h-auto object-contain">
                        </div>
                    </div>
                    <div class="mt-8 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-2 gap-8">
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Mecanum wheels</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=movement_short_o9zp8a&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Mecanum wheels"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Change max speed</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=change_max_speed_fghv2h&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Change max speed"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                    </div>
                </section>
                
                <hr class="standard-hr">
                <!-- Arm Movement Section -->
                <section id="robotic-arm" class="standard-section">
                    <h3 class="section-title">Robotic Arm</h3>
                    <div class="grid md:grid-cols-12 gap-8 items-center">
                        <div class="md:col-span-8">
                            <p class="standard-text">
                                The robotic arm has 6 motors, giving it 6 Degrees of Freedom (DoF), which allows it to reach a
                                wide range of positions and orientations. The 1st motor controls the base rotation, motors 2, 3
                                and 4 can bend the arm at different points, the 5th motor controls the gripper rotation, and the
                                6th motor opens and closes the gripper.
                                <br>
                                The arm has three different control modes.</p>
                            <ul class="first-level">
                                <li><strong>Direct motor control:</strong> control each motor individually using the
                                    controller. It is not very intuitive, since you need 2 buttons or 1 rocker for each
                                    motor (forward and backward movements), for a total of 12 buttons.</li>
                                <li><strong>Inverse kinematics:</strong> in this mode, you control the position of the
                                    gripper (up-down, left-right, forward-backward), and an algorithm calculates the motor
                                    movements necessary to reach that position. It is more intuitive to use, and requires
                                    fewer buttons (10 instead of 12). That is because the 4 controls for motors 1 to 4 are
                                    substituted with controls for the 3 axes of a 3D position in space. Currently, this
                                    mode is noticeably slow because the main computer can't complete the computations fast
                                    enough. It uses the
                                    <a href="https://ikpy.readthedocs.io/en/latest/ikpy.html" class="standard-link">IKPy library</a>
                                    to calculate inverse kinematics.
                                <li><strong>Memorized positions:</strong> the arm can move between memorized positions.
                                    There are 4 buttons on the controller that can be used to memorize and recall
                                    positions (they are set with predefined, useful positions that can be overwritten).
                                    A long press (2 seconds) memorizes the current position, while a click makes the arm
                                    reach the memorized position.</li>
                            </ul>
                            <p class="standard-text">
                                Finally, it is possible to unlock the arm motors with the
                                controller, so that it can be moved manually (for example to memorize a position).
                                The arm is automatically extended forward when you start using it, and folded back when
                                you stop using it. This is done to save space and avoid collisions with the environment.
                            </p>
                        </div>
                        <div class="md:col-span-4">
                            <img src="assets/hardware/robotic_arm.png" alt="Mantis Robotic Arm" class="rounded-lg w-full h-auto object-contain">
                        </div>
                    </div>
                    <div class="mt-8 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8">
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Forward kinematics</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=robotic_arm_mqmijm&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Forward kinematics"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Inverse kinematics</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=inverse_kinematics_ktnd1s&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Inverse kinematics"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Memorized positions</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=arm_memorized_positions_few1rc&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Memorized positions"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                    </div>
                </section>

                <hr class="standard-hr">
                <!-- Computer Vision Section -->
                <section id="computer-vision" class="standard-section">
                    <h3 class="section-title">Computer Vision</h3>
                    <div class="grid md:grid-cols-12 gap-8 items-center">
                        <div class="md:col-span-7">
                            <p class="standard-text">
                                Mantis is equipped with a frontal camera that allows it to see its surroundings and uses
                                <a href="https://docs.ultralytics.com/" class="standard-link">YOLO
                                    (You Only Look Once)</a> to detect objects in real time. YOLO models can detect about 80
                                different categories including people, animals, vehicles, tools, toys, electronic devices, etc.
                                It is free and works very well. It is also relatively easy to fine-tune models, so you can
                                customize it to your needs.
                            </p>
                            <p class="standard-text">
                                On the robot are present four YOLO models (the latest at the time of the development): v11 large
                                for TPU, v11 medium for TPU, v11 small for TPU, v11 small standard. YOLO on the main computer is
                                very slow (about 30 seconds to examine a single image, but it depends on the model dimension).
                                That is why, if it is present, the robot will automatically run the models on the Coral TPU, which
                                is about 10 times faster. It, however, needs the model to be converted to a specific format,
                                that is why three of them are "for TPU". The "standard" model is used automatically if no TPU is
                                found at runtime.
                                Depending on the trade-offs you want to make, you can choose the smaller and faster models, or
                                the larger and more accurate ones. You can also easily add your own models, as long as they
                                are in the correct format.
                            </p>
                        </div>
                        <div class="md:col-span-5">
                            <img src="assets/capabilities/yolo_capabilities.png" alt="YOLO Capabilities" class="rounded-lg w-full h-auto object-contain">
                        </div>
                    </div>
                    <div class="mt-8 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-2 gap-8">
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">YOLO object recognition example</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=yolo_example_intocg&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="YOLO object detection"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                    </div>
                </section>

                <hr class="standard-hr">
                <!-- Autonomous Agent (Vision) -->
                <section id="autonomous-agent-vision" class="standard-section">
                    <h3 class="section-title">Autonomous Agent (Vision)</h3>
                    <div class="grid md:grid-cols-12 gap-8 items-center">
                        <div class="md:col-span-7">
                            <p class="standard-text">
                                Mantis can autonomously navigate its environment using computer vision (the YOLO models
                                described before). In this mode, the robot uses the camera to search for a specific target (must
                                be chosen among the 80 categories supported by YOLO), and then moves toward it. The search at
                                the moment is a simple rotation of in place, but it can be improved in the future to be more
                                sophisticated.
                            </p>
                            <p class="standard-text"><strong>Note 1:</strong> if a 2-color led is properly
                                connected to the GPIO pins, it will stay red while the robot is "thinking" (examining a
                                frame). After each frame it will blink green if the target is found, orange otherwise.
                            </p>
                            <p class="standard-text"><strong>Note 2:</strong> if the lidar is connected,
                                the robot measures the distance to the target and stops when it is close enough (about
                                20 cm), and emits a beep. If the lidar is not connected, it will keep going until it
                                collides with the target, or the target is not recognised anymore (it often happens
                                because it can't fit in the camera images at close distances).
                            </p>
                            <p class="standard-text">
                                The YOLO model used by the Autonomous Agent can be changed at runtime with the controller: it
                                cycles through the models present in a specific folder, so that you can add and remove
                                models as you wish. The target can also be changed at runtime, by pressing a button
                                on the controller, which cycles through the categories supported by YOLO. For convenience,
                                you can specify a subset of categories in the configuration file, so that you don't have to
                                cycle through all 80 categories.
                            </p>
                        </div>
                        <div class="md:col-span-5">
                            <img src="https://res.cloudinary.com/dywsmv4ow/image/upload/v1755540187/frontal_camera_ur442q.jpg" alt="Forward Camera" class="rounded-lg w-full h-auto object-contain">
                        </div>
                    </div>
                    <div class="mt-8 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-2 gap-8">
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Search cat (lidar active)</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=vision_agent_lidar_y7uaq2&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Autonomous agent (vision) with lidar"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Search cat (lidar inactive)</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=vision_agent_no_lidar_ebxe74&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Autonomous agent (vision) without lidar"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                    </div>
                </section>

                <hr class="standard-hr">
                <!-- Autonomous Agent (Sound) -->
                <section id="autonomous-agent-sound" class="standard-section">
                    <h3 class="section-title">Autonomous Agent (Sound)</h3>
                    <div class="grid md:grid-cols-12 gap-8 items-center">
                        <div class="md:col-span-7">
                            <p class="standard-text">
                                In this mode, the robot autonomously goes toward the nearest sound source. It uses the
                                ReSpeaker Mic Array v2.0 to detect the sound direction, and then moves toward it.
                            </p>
                            <p class="standard-text"><strong>Note:</strong> sounds need to be continuous and loud
                                enough to surpass the noise generated by the robot itself. Otherwise, the robot will start
                                following its own motors, making it just spin in place.
                            </p>
                        </div>
                        <div class="md:col-span-5">
                            <img src="assets/hardware/microphone.png" alt="ReSpeaker Mic Array v2.0" class="rounded-lg w-full h-auto max-h-[350px] object-contain">
                        </div>
                    </div>
                    <div class="mt-8 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-2 gap-8">
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Chase sound source</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=VID_20250329_162817_oskaac&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Autonomous agent (sound)"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                    </div>
                </section>

                <hr class="standard-hr">
                <!-- Voice Interaction -->
                <section id="voice-interaction" class="standard-section">
                    <h3 class="section-title">Voice Interaction</h3>
                    <div class="grid md:grid-cols-12 gap-8 items-center">
                        <div class="md:col-span-8">
                            <p class="standard-text">
                                Mantis can interact with the user via spoken commands. It understands natural language
                                (many languages are supported) and can:
                            </p>
                            <ul class="first-level">
                                <li>respond through the speakers (often it responds in English unless
                                    explicitly asked to do it in a different language).</li>
                                <li>execute various robot functions. Es. move the robot (you can specify direction, velocity
                                    and duration), move the arm (it uses inverse kinematics to accept intuitive commands),
                                    use the arm's camera, sound the buzzer, increase/decrease max speed...</li>
                                <li>access the robotic arm's camera to add visual information to the conversation.</li>
                            </ul>
                            <p class="standard-text">
                                It uses the ReSpeaker Mic Array v2.0 to recognize voices and filter out other sounds. The voice
                                interaction is powered by Google's
                                <a href="https://ai.google.dev/gemini-api/docs" class="standard-link">Gemini API</a>.
                                Each time the robot is powered on, it is a new session, but within the session it has memory of
                                the conversation, so you can ask follow-up questions, and it will remember what you said before.
                            </p>
                            <p class="standard-text">
                                <strong>Note 1:</strong> in my experience, you need to speak quite loudly for this mode to work well.
                            </p>
                            <p class="standard-text">
                                <strong>Note 2:</strong> this capability requires internet connection, since the models are not
                                hosted locally on the robot.
                            </p>
                            <p class="standard-text">
                                <strong>Note 3:</strong> you will need to create an account and put your API key on the robot
                                to use this feature. With the free tier, you have a limited number of requests per minute and
                                per day, but it is still usable.
                            </p>
                        </div>
                        <div class="md:col-span-4">
                            <img src="assets/capabilities/speakers_and_microphone.jpg" alt="Voice Interaction" class="rounded-lg w-full h-auto object-contain">
                        </div>
                    </div>
                    <div class="mt-8 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8">
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Talk and move</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=voice_interaction_generic_correction_uct9qd&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Respond and move"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Control arm</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=voice_interaction_arm_short_bhuerw&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Control arm"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Camera interaction</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=voice_interaction_camera_collage_z1rfcm&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Camera interaction"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                    </div>
                </section>

                <hr class="standard-hr">
                <!-- Obstacle Avoidance -->
                <section id="obstacle-avoidance" class="standard-section">
                    <h3 class="section-title">Obstacle Avoidance</h3>
                    <div class="grid md:grid-cols-12 gap-8 items-center">
                        <div class="md:col-span-7">
                            <p class="standard-text">
                                Mantis is equipped with a lidar that allows it to detect obstacles in its path. In
                                "normal" mode (when the user controls the robot movements), the lidar can be activated.
                                When it is active, the robot will stop if an obstacle is detected in the direction
                                of the movement, and will emit a beep.
                                <br>Irrespective of any obstacles, rotation is always allowed.
                            </p>
                            <p class="standard-text"><strong>Note:</strong> The lidar is partially occluded
                                by the robot's own components, so it can only detect obstacles in front of it, and to
                                the sides, but not behind it. For now, when active, it will always block the robot from
                                moving backward, but I plan to change it and always allow the robot to move backward
                                instead.
                            </p>
                        </div>
                        <div class="md:col-span-5">
                            <img src="assets/hardware/lidar.png" alt="Lidar" class="rounded-lg w-full h-auto max-h-[350px] object-contain">
                        </div>
                    </div>
                    <div class="mt-8 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-2 gap-8">
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Obstacle detection</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=Lidar_nn8h7g&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Obstacle detection"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">Obstacle avoidance</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=obstacle_avoidance_y3tfpr&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="Obstacle avoidance"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                    </div>
                </section>

                <hr class="standard-hr">
                <!-- VR Connection -->
                <section id="vr-connection" class="standard-section">
                    <h3 class="section-title">VR Connection</h3>
                    <div class="grid md:grid-cols-12 gap-8 items-center">
                        <div class="md:col-span-7">
                            <p class="standard-text">
                                Mantis can be controlled using a VR headset. The connection is made through a custom app that
                                allows you to see through the robot's camera and control its movements using the VR controllers.
                                The communication is done through ROS2 (Robot Operating System 2), over Wi-Fi, or the robot's
                                own hotspot if no Wi-Fi is available. The app is built with Unity and is available on GitHub
                                (the already built apk).
                            </p>
                            <p class="standard-text"><strong>Note 1:</strong>
                                I have only tested the app with the
                                <a href="https://www.meta.com/quest/quest-3/" class="standard-link">Meta Quest 3</a>
                                headset.
                            </p>
                            <p class="standard-text"><strong>Note 2:</strong> the app is relatively old, so support
                                for the arm and other features are not present. For the same reason, some of the libraries (es.
                                VR support for Unity) have probably changed significantly.
                            </p>
                        </div>
                        <div class="md:col-span-5">
                            <img src="assets/hardware/vr_headset.png" alt="VR Headset" class="rounded-lg w-full h-auto max-h-[350px] object-contain">
                        </div>
                    </div>
                    <div class="mt-8 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-2 gap-8">
                        <div class="aspect-w-16 aspect-h-9 overflow-hidden p-4">
                            <h4 class="element-title">VR control</h4>
                            <iframe
                                    src="https://player.cloudinary.com/embed/?cloud_name=dywsmv4ow&public_id=Robot_VR_g00ekm&profile=cld-default"
                                    width="640"
                                    height="360"
                                    title="VR Control"
                                    style="height: auto; width: 100%; aspect-ratio: 640 / 360;"
                                    allow="fullscreen; encrypted-media; gyroscope"
                                    allowfullscreen
                            ></iframe>
                        </div>
                    </div>
                </section>

            </div>
        </main>
    </div>
</div>


<!-- Image Modal -->
<div id="image-modal" class="hidden fixed inset-0 bg-black bg-opacity-75 z-50 flex items-center justify-center p-4" onclick="closeModal()">
    <span class="absolute top-4 right-6 text-white text-4xl font-bold cursor-pointer">&times;</span>
    <img id="modal-image" class="max-w-full max-h-full rounded-lg" src="" alt="Full-size capability image">
</div>

<div id="footer-placeholder"></div>
<script src="main.js"></script>
</body>
</html>
